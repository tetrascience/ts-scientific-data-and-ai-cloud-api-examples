{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8b97ef7b",
            "metadata": {
                "id": "8b97ef7b"
            },
            "source": [
                "\n",
                "# Migrating pipelines between platform instances\n",
                "\n",
                "For full details on pipeline migration, see: [Pipeline Migration Strategies](https://tetrascience.zendesk.com/hc/en-us/articles/30900243788173-Pipeline-Migration-Strategies)\n\nThis notebook is provided for reference, and can be modified with your source and target TDP environments and authorization tokens to migrate one or more pipelines. We recommend reading and running each code block individually in Jupyter Notebook, VSCode, Google Colab, or your preferred platform to review the results and select the pipelines at each step.\n"
                "\n",
                "Note: pipelines use a protocol (which uses task-scripts). The protocols of migrated pipelines need to be accessible in the destination org."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install itables[widget]\n",
                "!pip install jmespath"
            ],
            "metadata": {
                "collapsed": true,
                "id": "Wz1RIFYPXw_m"
            },
            "id": "Wz1RIFYPXw_m",
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "id": "deaec127",
            "metadata": {
                "id": "deaec127"
            },
            "source": [
                "## Import statements"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ff0d707",
            "metadata": {
                "id": "3ff0d707"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import requests\n",
                "import pandas as pd\n",
                "from itables.widget import ITable\n",
                "import jmespath as jp"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d177a0f",
            "metadata": {
                "id": "1d177a0f"
            },
            "source": [
                "## Notebook Parameters\n",
                "* SAVE_DIR = directory on your local machine\n",
                "\n",
                "### Source Platform\n",
                "* FILENAME_SOURCE = name for the authentication file, e.g. auth-dev.json\n",
                "* API_URL_SOURCE = API URL for your TDP instance, e.g. https://api.tetrascience-dev.com/v1/\n",
                "* AUTH_TOKEN_SOURCE = personal access token for TDP, or token of Service User\n",
                "* TDP_ORG_SOURCE = organization slug for configuration report\n",
                "\n",
                "### Destination Platform\n",
                "* FILENAME_DEST = name for the authentication file, e.g. auth-prod.json\n",
                "* API_URL_DEST = API URL for your TDP instance, e.g. https://api.tetrascience.com/v1/\n",
                "* AUTH_TOKEN_DEST = personal access token for TDP, or token of Service User\n",
                "* TDP_ORG_DEST = organization slug for configuration report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2eb6ad2a",
            "metadata": {
                "id": "2eb6ad2a"
            },
            "outputs": [],
            "source": [
                "SAVE_DIR = \".\"\n",
                "\n",
                "FILENAME_DEST = \"auth-uat.json\"\n",
                "API_URL_DEST = \"https://api.tetrascience-uat.com/v1\"\n",
                "AUTH_TOKEN_DEST = \"**********\"\n",
                "TDP_ORG_DEST = \"**********\"\n",
                "\n",
                "FILENAME_SOURCE = \"auth-dev.json\"\n",
                "API_URL_SOURCE = \"https://api.tetrascience-dev.com/v1\"\n",
                "AUTH_TOKEN_SOURCE = \"**********\"\n",
                "TDP_ORG_SOURCE = \"**********\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fccc4e19",
            "metadata": {
                "id": "fccc4e19"
            },
            "source": [
                "## Create authentication files\n",
                "\n",
                "This uses the notebook parameters to create an authentication file for the source and target TDP systems, as outlined in the documentation for setting up your development environment: [Development Setup](https://developers.tetrascience.com/docs/set-up-your-environment-and-initialize-ts-sdk#configure-tdp-dependencies-and-authentication)\n",
                "\n",
                "This authentication file can also be used with our ts-sdk to deploy custom pipelines."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e1d118e",
            "metadata": {
                "id": "2e1d118e"
            },
            "outputs": [],
            "source": [
                "def create_authentication_file(filename, save_directory, api_url, auth_token, tdp_org, ignore_ssl=False):\n",
                "    auth_json_path = os.path.join(save_directory, filename)\n",
                "    if ignore_ssl:\n",
                "        ssl = \"true\"\n",
                "    else:\n",
                "        ssl = \"false\"\n",
                "    with open(auth_json_path, \"w\") as f:\n",
                "        auth_json = {\"api_url\": api_url,\n",
                "                     \"auth_token\": auth_token,\n",
                "                     \"org\": tdp_org,\n",
                "                     \"ignore_ssl\": ssl}\n",
                "        json.dump(auth_json, f, indent = 4)\n",
                "\n",
                "\n",
                "# create auth file for source\n",
                "create_authentication_file(FILENAME_SOURCE, SAVE_DIR, API_URL_SOURCE, AUTH_TOKEN_SOURCE, TDP_ORG_SOURCE)\n",
                "\n",
                "\n",
                "# create auth file for destination\n",
                "create_authentication_file(FILENAME_DEST, SAVE_DIR, API_URL_DEST, AUTH_TOKEN_DEST, TDP_ORG_DEST)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8d85960",
            "metadata": {
                "id": "e8d85960"
            },
            "source": [
                "\n",
                "## Use authentication files for API headers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4a3f426",
            "metadata": {
                "id": "a4a3f426"
            },
            "outputs": [],
            "source": [
                "# API headers for source\n",
                "with open(os.path.join(SAVE_DIR, FILENAME_SOURCE), \"r\") as f:\n",
                "    auth_data_source = json.loads(f.read())\n",
                "\n",
                "headers_source = {\"ts-auth-token\": auth_data_source[\"auth_token\"],\n",
                "               \"x-org-slug\": auth_data_source[\"org\"]}\n",
                "\n",
                "\n",
                "\n",
                "# API headers for destination\n",
                "with open(os.path.join(SAVE_DIR, FILENAME_DEST), \"r\") as f:\n",
                "    auth_data_dest = json.loads(f.read())\n",
                "\n",
                "headers_dest = {\"ts-auth-token\": auth_data_dest[\"auth_token\"],\n",
                "               \"x-org-slug\": auth_data_dest[\"org\"],\n",
                "               'Content-Type': 'application/json'}  # Sending pipeline details (json) to destination"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "835a2f15",
            "metadata": {
                "id": "835a2f15"
            },
            "outputs": [],
            "source": [
                "headers_source"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7548c643",
            "metadata": {
                "id": "7548c643"
            },
            "outputs": [],
            "source": [
                "headers_dest"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e9005084",
            "metadata": {
                "id": "e9005084"
            },
            "source": [
                "## Set up API endpoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a64e1508",
            "metadata": {
                "id": "a64e1508"
            },
            "outputs": [],
            "source": [
                "API_URL_SOURCE = auth_data_source[\"api_url\"]\n",
                "API_URL_DEST = auth_data_dest[\"api_url\"]\n",
                "PIPELINE_SEARCH = \"/pipeline/search\"\n",
                "PIPELINE_CREATION = \"/pipeline/create\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9388198e",
            "metadata": {
                "id": "9388198e"
            },
            "source": [
                "## Get all pipelines\n",
                "\n",
                "These are general functions to fetch pipelines from TDP. Note that this only fetches all enabled pipelines."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce63fb18",
            "metadata": {
                "id": "ce63fb18"
            },
            "outputs": [],
            "source": [
                "def get_pipeline_page(api_url, headers, **kwargs):\n",
                "    \"\"\"\n",
                "        Returns a set of pipelines and whether there are more\n",
                "        pipelines remaining\n",
                "        Optional args: page_size, page_index\n",
                "    \"\"\"\n",
                "    pipeline_api = api_url + PIPELINE_SEARCH + \"?\"\n",
                "    if \"index\" in kwargs.keys():\n",
                "        page_index = kwargs[\"index\"]\n",
                "        pipeline_api += \"from=\" + str(page_index) + \"&\"\n",
                "    if \"size\" in kwargs.keys():\n",
                "        page_size = kwargs[\"size\"]\n",
                "        pipeline_api += \"size=\" + str(page_size) + \"&\"\n",
                "    pipeline_api += \"pipelineStatus=enabled\"\n",
                "\n",
                "    print(pipeline_api)\n",
                "    print(headers)\n",
                "    pipeline_response = requests.get(pipeline_api, headers=headers)\n",
                "    pipeline_response = json.loads(pipeline_response.text)\n",
                "\n",
                "    print(pipeline_response)\n",
                "    return pipeline_response[\"hits\"], pipeline_response[\"hasNext\"]\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "def get_all_pipelines(api_url, headers, size=10):\n",
                "    \"\"\"\n",
                "        Returns list of all pipelines by iterating over full list\n",
                "        by the size parameter.\n",
                "    \"\"\"\n",
                "    hasNext = True\n",
                "    index = 0\n",
                "    all_pipelines = []\n",
                "    while hasNext == True:\n",
                "        pipes, hasNext = get_pipeline_page(api_url, headers, size=size, index=index)\n",
                "        all_pipelines += pipes\n",
                "        index += 1\n",
                "    return all_pipelines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d60bebe7",
            "metadata": {
                "id": "d60bebe7"
            },
            "outputs": [],
            "source": [
                "source_pipelines = get_all_pipelines(API_URL_SOURCE, headers_source)"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Summarize pipelines and check for potential dependencies\n",
                "Show a tabulation of the pipelines fetched from the TDP instance and highlight dependencies based on:\n",
                "\n",
                "* pipeline chaining\n",
                "* secrets and shared settings\n",
                "* source ID\n",
                "* possible hard coded values in scripts"
            ],
            "metadata": {
                "id": "1GE4a-AzeNWf"
            },
            "id": "1GE4a-AzeNWf"
        },
        {
            "cell_type": "code",
            "source": [
                "def check_dependencies(pipeline):\n",
                "    \"\"\"\n",
                "    scans the pipeline config for possible dependency on secrets, settings, scripts or preceeding pipelines\n",
                "\n",
                "    \"\"\"\n",
                "    dependency = \"\"\n",
                "\n",
                "    query =  \"triggerCondition.groups[?groups[?key=='pipelineId']] | length(@) > `0`\"\n",
                "    dependency = dependency + \"pipeline chaining<br>\" if jp.search(query, pipeline) else dependency\n",
                "\n",
                "    query = \"pipelineConfig.*.ssm\"\n",
                "    dependency = dependency + \"configured secrets<br>\" if jp.search(query, pipeline) else dependency\n",
                "\n",
                "    query = \"triggerCondition.groups[?groups[?key=='sourceId']] | length(@) > `0`\"\n",
                "    dependency = dependency + \"defined source ID<br>\" if jp.search(query, pipeline) else dependency\n",
                "\n",
                "    query = \"pipelineConfig.script\"\n",
                "    dependency = dependency + \"hardcoded values in script<br>\" if jp.search(query, pipeline) else dependency\n",
                "\n",
                "    dependency = \"check for \" + dependency if dependency else \"\"\n",
                "\n",
                "    return dependency\n",
                "\n",
                "\n",
                "def summarize_pipelines(pipelines):\n",
                "\n",
                "    \"\"\"\n",
                "    create a tabulation of the pipelines\n",
                "    \"\"\"\n",
                "\n",
                "    KEYS_TO_EXTRACT=[\"id\", \"name\",\"status\",\"protocolSlug\",\"protocolVersion\", \"description\" ]\n",
                "\n",
                "    pipeline_tabulation = []\n",
                "\n",
                "\n",
                "    for pipeline in pipelines:\n",
                "        pipeline_copy = {key: pipeline[key] for key in KEYS_TO_EXTRACT if key in pipeline}\n",
                "        dependencies = {\"possible dependencies\": check_dependencies(pipeline)}\n",
                "        # Create a new dictionary with dependencies first\n",
                "        ordered_pipeline_copy = {**dependencies, **pipeline_copy}\n",
                "        pipeline_tabulation.append(ordered_pipeline_copy )\n",
                "\n",
                "\n",
                "    return pd.DataFrame.from_dict(pipeline_tabulation)"
            ],
            "metadata": {
                "id": "iFE9U-4OYrE2"
            },
            "id": "iFE9U-4OYrE2",
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c192c609",
            "metadata": {
                "id": "c192c609"
            },
            "outputs": [],
            "source": [
                "source_df = summarize_pipelines(source_pipelines)\n",
                "table = ITable(source_df, select=\"multi\", buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"], lengthMenu=[10, 20, 50], layout={\"top2Start\": \"pageLength\"})\n",
                "table"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e9eb94b",
            "metadata": {
                "id": "1e9eb94b"
            },
            "source": [
                "## Get selected pipelines to migrate\n",
                "\n",
                "Select the pipelines to migrate by clicking row of interest in the table above"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c24d18f4",
            "metadata": {
                "id": "c24d18f4"
            },
            "outputs": [],
            "source": [
                "selected_pipeline_ids = table.df.iloc[table.selected_rows]['id'].tolist()\n",
                "selected_pipeline_ids"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1b1e8cad",
            "metadata": {
                "id": "1b1e8cad"
            },
            "source": [
                "## Create pipeline configuration and review selection"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5bb191ca",
            "metadata": {
                "id": "5bb191ca"
            },
            "source": [
                "Create the filtered JSON pipeline definition(s)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96dff377",
            "metadata": {
                "id": "96dff377"
            },
            "outputs": [],
            "source": [
                "selected_pipelines = [pipeline for pipeline in source_pipelines if pipeline['id'] in selected_pipeline_ids]\n",
                "\n",
                "selected_df = summarize_pipelines(selected_pipelines)\n",
                "table = ITable(selected_df, select=\"multi\", buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"], lengthMenu=[10, 20, 50], layout={\"top2Start\": \"pageLength\"})\n",
                "table"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "##Create pipelines in destination"
            ],
            "metadata": {
                "id": "xrXlCI3z5TIC"
            },
            "id": "xrXlCI3z5TIC"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1d106713",
            "metadata": {
                "id": "1d106713"
            },
            "outputs": [],
            "source": [
                "PIPELINE_CONFIG_KEYS_DONT_COPY = [\"createdAt\", \"id\", \"status\", \"updatedAt\", \"orgSlug\", \"clusterId\", \"artifactType\"]\n",
                "\n",
                "def copy_pipelines(pipelines):\n",
                "    \"\"\"\n",
                "    copy the pipeline config without the undesired keys\n",
                "    \"\"\"\n",
                "    new_pipelines = []\n",
                "    for pipeline in pipelines:\n",
                "        pipeline= {\n",
                "            k: v\n",
                "            for k,v in pipeline.items()\n",
                "            if k not in PIPELINE_CONFIG_KEYS_DONT_COPY\n",
                "        }\n",
                "        new_pipelines.append(pipeline)\n",
                "    return new_pipelines\n",
                "\n",
                "def create_pipelines(api_url, headers, pipelines):\n",
                "    \"\"\"\n",
                "        Creates pipeline from a list of pipelines in provided org.\n",
                "        For each pipeline, it will also print out the API call message.\n",
                "    \"\"\"\n",
                "    created_pipelines = []\n",
                "    for pipeline in pipelines:\n",
                "        print(\"Copying %s\" %pipeline[\"name\"])\n",
                "        payload = json.dumps(pipeline)\n",
                "        api_call = requests.post(api_url+PIPELINE_CREATION, headers=headers, data=payload)\n",
                "        print(api_call.text)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a67c8dc",
            "metadata": {
                "id": "1a67c8dc"
            },
            "outputs": [],
            "source": [
                "new_pipelines = copy_pipelines(selected_pipelines)\n",
                "summarize_pipelines(new_pipelines)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8bc65010",
            "metadata": {
                "id": "8bc65010"
            },
            "outputs": [],
            "source": [
                "# This line will make the API call and create the pipelines in destination\n",
                "\n",
                "create_pipelines(API_URL_DEST, headers_dest, new_pipelines)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        },
        "colab": {
            "provenance": []
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}